# ğŸ¤– AutomatizaciÃ³n de AnÃ¡lisis de Laboratorio QuÃ­mico con n8n

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto automatiza el anÃ¡lisis de datos del laboratorio quÃ­mico utilizando **n8n** como orquestador de workflows y **Python** para anÃ¡lisis cientÃ­fico avanzado. El sistema procesa datos de producciÃ³n de equipos de laboratorio, almacena informaciÃ³n en PostgreSQL y genera estadÃ­sticas automÃ¡ticas.

### ğŸ¯ **Estado Actual: CONFIGURADO Y EN PRUEBAS âœ…**
- âœ… **Docker Compose**: Servicios n8n y PostgreSQL funcionando
- âœ… **Base de Datos**: Esquemas sincronizados y optimizados
- âœ… **Workflows**: JSON Lab Data Processing activo cada 2 minutos
- âœ… **Datos de Prueba**: Procesando CSV original con 74 registros
- ğŸ§ª **Modo Testing**: Validando automatizaciÃ³n antes de producciÃ³n

## ğŸ§ª Datos Procesados por el Sistema

### **Equipos del Laboratorio Monitoreados:**
- **ğŸ”¬ pHmetro** - MediciÃ³n de pH en muestras quÃ­micas
- **ğŸ“Š EspectrofotÃ³metro** - AnÃ¡lisis espectral de compuestos quÃ­micos
- **ğŸŒ€ CentrÃ­fuga** - SeparaciÃ³n de componentes quÃ­micos
- **ğŸ©¸ Analizador HematolÃ³gico** - AnÃ¡lisis de muestras biolÃ³gicas
- **ğŸ“ˆ Control de Turnos** - Seguimiento por turnos (maÃ±ana/tarde/noche)
- **ğŸ“Š MÃ©tricas de Rendimiento** - AnÃ¡lisis de eficiencia y calidad

### **Estructura de Datos Actual:**
```json
{
  "record_id": 1,
  "fecha": "2025-09-29",
  "equipo": "phmetro",
  "turno": "maÃ±ana",
  "muestras_procesadas": 85,
  "rendimiento": 78,
  "comentario": "ok",
  "tipo_muestra": "QuÃ­mica",
  "estado": "Aprobado"
}
```

### **Tablas de Base de Datos:**
- **`processed_lab_data`**: Datos individuales de cada anÃ¡lisis (actualmente 0 registros - limpia)
- **`lab_statistics`**: EstadÃ­sticas agregadas por fecha (actualmente 0 registros - limpia)

## ğŸ”„ Workflows Implementados

### **ğŸ“Š 1. JSON Lab Data Processing** (json-data-processing-workflow.json) âœ… ACTIVO
**PropÃ³sito:** Procesamiento automÃ¡tico y continuo de datos de laboratorio quÃ­mico

**ğŸ§ª CONFIGURACIÃ“N DE PRUEBA ACTUAL:**
- **Schedule Trigger**: Se ejecuta cada **2 minutos** para efectos de testing y validaciÃ³n
- **Fuente de Datos**: Procesa el archivo CSV original `produccion_limpia_final.csv` (no datos externos)
- **Objetivo**: Validar que la automatizaciÃ³n funciona correctamente antes de configurar intervalos de producciÃ³n

**Funcionalidad:**
- **Lectura de CSV Original**: Lee directamente el archivo `produccion_limpia_final.json` generado desde el CSV
- **Procesamiento de Datos Reales**: Utiliza los 74 registros originales del laboratorio quÃ­mico
- **GeneraciÃ³n de IDs Ãšnicos**: Asigna identificadores Ãºnicos a cada registro procesado
- **ClasificaciÃ³n AutomÃ¡tica**: 
  - **Tipo de muestra**: Todas clasificadas como 'QuÃ­mica'
  - **Estado**: Aprobado si rendimiento â‰¥ 70%, Rechazado si < 70%
- **Almacenamiento Dual**:
  - Tabla `lab_statistics`: ResÃºmenes agregados por fecha
  - Tabla `processed_lab_data`: Registros individuales con estructura quÃ­mica completa

**Estructura de Datos del CSV Original:**
```json
{
  "record_id": "LAB_001",
  "fecha": "2025-09-29",
  "equipo": "phmetro",
  "turno": "maÃ±ana", 
  "muestras_procesadas": 85,
  "rendimiento": 78.5,
  "comentario": "AnÃ¡lisis completado correctamente",
  "tipo_muestra": "QuÃ­mica",
  "estado": "Aprobado",
  "fecha_procesamiento": "2025-09-29T14:38:59Z"
}
```

**Flujo de EjecuciÃ³n de Prueba:**
```
â° Schedule (2min) â†’ ğŸ“„ Read CSV â†’ ğŸ”„ Parse JSON â†’ ğŸ“Š Process Records â†’ ğŸ’¾ Save to DB
```

**ğŸ¯ MÃ©tricas de ValidaciÃ³n:**
- **Registros esperados**: 74 (del CSV original)
- **Frecuencia de prueba**: Cada 2 minutos
- **Tablas actualizadas**: `processed_lab_data` y `lab_statistics`
- **ValidaciÃ³n**: Verificar que no se generen duplicados y que todos los registros se procesen correctamente

---

## ğŸ”§ **CONFIGURACIÃ“N ACTUAL DE PRUEBAS**

### âœ… **Modo Testing Activado**
- **Frecuencia**: Cada **2 minutos** (en lugar de 1 hora de producciÃ³n)
- **Fuente de datos**: CSV original `produccion_limpia_final.csv` (74 registros reales)
- **Objetivo**: Validar funcionamiento completo de la automatizaciÃ³n
- **Base de datos**: Limpia y lista para recibir datos de prueba

### ğŸ¯ **Validaciones en Curso**
- **Conectividad**: n8n â†” PostgreSQL âœ…
- **Lectura de archivos**: CSV/JSON processing âœ…  
- **Esquemas de BD**: Columnas sincronizadas âœ…
- **Procesamiento**: TransformaciÃ³n de datos âœ…
- **Almacenamiento**: InserciÃ³n en tablas âœ…

### ğŸ“Š **Resultados Esperados de Prueba**
- **Tabla `processed_lab_data`**: 74 registros (uno por cada fila del CSV)
- **Tabla `lab_statistics`**: 1+ registros con estadÃ­sticas agregadas
- **Frecuencia de actualizaciÃ³n**: Cada 2 minutos
- **Sin duplicados**: Cada ejecuciÃ³n debe procesar los mismos 74 registros sin duplicar

### ğŸ”„ **TransiciÃ³n a ProducciÃ³n**
Una vez validado el funcionamiento en modo prueba:
1. **Cambiar frecuencia** de 2 minutos â†’ 1 hora (o segÃºn necesidades)
2. **Configurar fuentes externas** (APIs, webhooks, etc.)
3. **Activar monitoreo** y sistema de alertas
4. **Implementar backup** y recuperaciÃ³n de datos

---

## ğŸ”§ **HISTORIAL DE CORRECCIONES Y MEJORAS**

### âœ… **Problema de Duplicados Resuelto**
- **Problema identificado**: Schedule Trigger configurado a 30 segundos causaba duplicaciÃ³n excesiva de registros
- **SÃ­ntomas**: 45+ registros en lugar de los 37 esperados del CSV
- **SoluciÃ³n implementada**: 
  - Cambio de frecuencia de 30 segundos â†’ 1 hora (3600 segundos)
  - Limpieza completa de la base de datos
  - EliminaciÃ³n de registros duplicados
- **Estado actual**: Base de datos limpia (0 registros) lista para procesamiento correcto

### ğŸ¯ **Estrategia de Frecuencia Basada en Fuente de Datos**
- **ğŸ“„ Fuente EstÃ¡tica (CSV)**: 1 hora - Evita duplicados innecesarios de datos que no cambian
- **ğŸŒ Fuente DinÃ¡mica (API Externa)**: Frecuencia mÃ¡s rÃ¡pida - Cuando se implemente conexiÃ³n a APIs externas
- **ğŸ’¡ Principio**: La frecuencia debe coincidir con la velocidad de cambio de los datos fuente
- **âš¡ Beneficio**: OptimizaciÃ³n de recursos y eliminaciÃ³n de datos redundantes

### ğŸ”„ **Optimizaciones Realizadas**:
- **AutomatizaciÃ³n inteligente**: Frecuencia ajustada segÃºn tipo de fuente de datos
- **Eficiencia de recursos**: ReducciÃ³n del 99.9% en frecuencia de ejecuciÃ³n para CSV estÃ¡tico
- **Calidad de datos**: EliminaciÃ³n de duplicados y datos inconsistentes
- **Monitoreo mejorado**: Orden lÃ³gico de ejecuciÃ³n de workflows establecido
- **Escalabilidad futura**: Preparado para aumentar frecuencia cuando se conecten APIs externas

---

## ğŸ“‹ **ORDEN LÃ“GICO DE EJECUCIÃ“N DE WORKFLOWS**

### ğŸ”„ **Secuencia Recomendada:**

#### **1. JSON Lab Data Processing** (Primero - Base de datos)
- **FunciÃ³n**: Procesa y almacena los datos del CSV en la base de datos
- **Frecuencia**: Cada 1 hora (optimizada para fuente estÃ¡tica CSV)
- **Por quÃ© primero**: Es la fuente de datos principal que alimenta las tablas
- **ğŸ’¡ Nota**: Frecuencia ajustada a 1 hora para evitar duplicados de datos estÃ¡ticos

#### **2. Lab Data Processing Pipeline** (Segundo - Opcional)
- **FunciÃ³n**: Procesa datos adicionales vÃ­a webhook
- **Trigger**: Manual o por API
- **Por quÃ© segundo**: Complementa los datos del primer workflow

#### **3. Lab Alert Monitoring** (Tercero - Monitoreo)
- **FunciÃ³n**: Monitorea los datos procesados y genera alertas
- **Frecuencia**: Cada 5 segundos
- **Por quÃ© Ãºltimo**: Necesita que los datos ya estÃ©n procesados

### âš ï¸ **Consideraciones Importantes:**
- El workflow de alertas **depende** de que haya datos en la base de datos
- El monitoreo (5 segundos) es mucho mÃ¡s frecuente que la generaciÃ³n de datos (1 hora)
- AsegÃºrate de que la base de datos tenga datos antes de activar el monitoreo
- **ğŸ”„ Escalabilidad**: Cuando se conecten fuentes externas (APIs), se podrÃ¡ reducir la frecuencia del procesamiento principal
- **ğŸ“Š Estado actual**: `JSON Lab Data Processing` estÃ¡ activo, `Lab Alert Monitoring` y `Lab Data Processing Pipeline` estÃ¡n inactivos

---

### **ğŸš€ 2. Lab Data Processing Pipeline** (lab-data-processing-workflow.json) 
**PropÃ³sito:** Pipeline completo para procesamiento de archivos de laboratorio quÃ­mico via webhook

**Funcionalidad:**
- **Webhook Trigger**: Recibe archivos via POST a `/lab-data-upload`
- **ValidaciÃ³n de Datos QuÃ­micos**: Verifica integridad y formato de archivos CSV/JSON
- **Procesamiento AsÃ­ncrono**: 
  - Extrae Job ID para seguimiento
  - Espera procesamiento (5 segundos)
  - Verifica estado de completitud
- **AnÃ¡lisis EstadÃ­stico QuÃ­mico**: 
  - Cuenta total de muestras procesadas por fecha
  - Verifica datos aprobados en `processed_lab_data`
  - Genera reportes automÃ¡ticos de equipos quÃ­micos
- **GestiÃ³n de Estados**:
  - âœ… Ã‰xito: NotificaciÃ³n y descarga de resultados
  - âŒ Error: Manejo de errores y reintentos
- **Almacenamiento**: Guarda en tabla `processed_lab_data` con estructura quÃ­mica
- **Respuesta Webhook**: Retorna estado final al cliente

**Estructura de Base de Datos:**
```sql
INSERT INTO processed_lab_data 
(record_id, fecha, equipo, turno, muestras_procesadas, rendimiento, comentario, tipo_muestra, estado)
VALUES (?, ?, ?, ?, ?, ?, ?, 'QuÃ­mica', ?)
```

**Flujo de EjecuciÃ³n:**
```
ğŸ“¤ Webhook Upload â†’ âœ… Validate â†’ ğŸ”„ Process â†’ â³ Wait â†’ ğŸ“Š Analyze â†’ ğŸ“§ Notify â†’ ğŸ“¥ Response
```

---

### **ğŸš¨ 3. Lab Alert Monitoring** (alert-monitoring-workflow.json)
**PropÃ³sito:** Sistema de monitoreo en tiempo real con alertas automÃ¡ticas para datos quÃ­micos

**Funcionalidad:**
- **Monitoreo Continuo**: Ejecuta cada 5 segundos (tiempo real)
- **ObtenciÃ³n de Datos QuÃ­micos**: Consulta API Gateway `/data/chemical-summary` para datos recientes (Ãºltimas 24h)
- **AnÃ¡lisis de AnomalÃ­as QuÃ­micas**:
  - ğŸ“‰ **Rendimiento quÃ­mico bajo** (<75% en anÃ¡lisis)
  - ğŸ”§ **Problemas de equipos quÃ­micos** (phmetro, espectrofotÃ³metro, centrÃ­fuga, analizador hematolÃ³gico)
  - ğŸ“Š **Baja producciÃ³n** (<50 muestras procesadas/dÃ­a)
  - ğŸ”„ **Alta tasa de repeticiones** (>20% de muestras requieren repetir)
  - âš–ï¸ **Desbalance de turnos** (distribuciÃ³n desigual entre maÃ±ana/tarde/noche)
- **Sistema de Alertas Multinivel**:
  - ğŸ”´ **CrÃ­ticas**: Rendimiento <60%, equipos fuera de servicio, repeticiones >30%
  - ğŸŸ¡ **Medias**: Rendimiento 60-75%, repeticiones 20-30%, baja producciÃ³n
  - â„¹ï¸ **Advertencias**: Desbalance de turnos, problemas menores
- **Notificaciones Inteligentes**:
  - Emails HTML formateados por severidad
  - IntegraciÃ³n con Slack para alertas crÃ­ticas
  - Escalamiento automÃ¡tico segÃºn criticidad

**MÃ©tricas Monitoreadas:**
```sql
SELECT 
  COUNT(*) as total_muestras_procesadas,
  AVG(rendimiento) as avg_rendimiento,
  COUNT(CASE WHEN estado = 'Repetir' THEN 1 END) * 1.0 / COUNT(*) as tasa_repeticiones,
  COUNT(DISTINCT equipo) as equipos_activos,
  COUNT(CASE WHEN turno = 'MaÃ±ana' THEN 1 END) as turno_manana,
  COUNT(CASE WHEN turno = 'Tarde' THEN 1 END) as turno_tarde,
  COUNT(CASE WHEN turno = 'Noche' THEN 1 END) as turno_noche
FROM processed_lab_data 
WHERE fecha >= CURRENT_DATE - INTERVAL '1 day' AND tipo_muestra = 'QuÃ­mica'
```

**Flujo de EjecuciÃ³n:**
```
â° Cron (5s) â†’ ğŸ“Š Get Data â†’ ğŸ” Analyze â†’ â“ Has Alerts? â†’ ğŸš¨ Notify â†’ ğŸ“ Log
```

---

### **ğŸ” 4. Credentials Setup** (credentials-setup.json)
**PropÃ³sito:** ConfiguraciÃ³n centralizada de credenciales para conexiones

**Funcionalidad:**
- **PostgreSQL**: Credenciales para base de datos del laboratorio
  - Host: `lab_postgres` (contenedor Docker)
  - Puerto: 5432 (interno)
  - Base de datos: `lab_analytics`
  - Usuario y contraseÃ±a encriptados
- **ConfiguraciÃ³n de Seguridad**: SSL deshabilitado para red interna Docker

**Archivos Procesados:**
- `data/produccion_limpia_final.json` (20 registros)
- `data/produccion_limpia_final.csv` (datos originales)

## ğŸ—ï¸ Arquitectura Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    JSON Data    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    SQL Insert   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     n8n     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  PostgreSQL  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Data Tables   â”‚
â”‚ (Scheduler) â”‚                 â”‚   Database   â”‚                 â”‚ lab_statistics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚processed_lab_dataâ”‚
      â”‚                                â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–¼                                â–¼                              
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               
â”‚ JSON Files  â”‚                â”‚   Docker     â”‚               
â”‚ CSV Data    â”‚                â”‚ Containers   â”‚               
â”‚ Scheduling  â”‚                â”‚   Network    â”‚               
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               
```

### **Componentes Activos:**
- **n8n**: Orquestador principal (puerto 5678)
- **PostgreSQL**: Base de datos (puerto 5433)
- **Docker Network**: `lab_network` para comunicaciÃ³n interna

## ğŸ”„ Flujo de AutomatizaciÃ³n Real

**Ejemplo de Uso Diario:**
```
ğŸ“‹ TÃ©cnico sube CSV quÃ­mico â†’ ğŸ¤– n8n valida â†’ ğŸ§ª Procesa datos quÃ­micos â†’ ğŸ’¾ Guarda en BD â†’ ğŸ“§ Supervisor recibe alerta
```

1. **Ingesta**: n8n detecta archivo CSV con datos quÃ­micos del dÃ­a
2. **ValidaciÃ³n**: Code Node verifica formato y completitud de datos quÃ­micos
3. **Procesamiento**: Analiza datos de equipos quÃ­micos y calcula mÃ©tricas
4. **AnÃ¡lisis**: DetecciÃ³n de anomalÃ­as en rendimiento quÃ­mico y cÃ¡lculo de KPIs
5. **Almacenamiento**: Guardado en PostgreSQL tabla `processed_lab_data` con estructura quÃ­mica
6. **Alertas**: Notificaciones inmediatas por problemas crÃ­ticos en equipos quÃ­micos
7. **Reportes**: GeneraciÃ³n automÃ¡tica de informes por turno y equipo quÃ­mico

**Base de Datos n8n:**
- **Tabla Principal**: `processed_lab_data` - Almacena todos los registros quÃ­micos individuales
- **Tabla EstadÃ­sticas**: `lab_statistics` - ResÃºmenes agregados por fecha
- **Estructura QuÃ­mica**: Campos especÃ­ficos para equipos de laboratorio quÃ­mico
- **Monitoreo**: Consultas SQL optimizadas para anÃ¡lisis en tiempo real

## ğŸš€ **INICIO RÃPIDO**

### **âš¡ Pasos para Activar el Sistema:**

1. **Verificar servicios activos:**
   ```bash
   docker-compose ps  # Verificar que n8n y PostgreSQL estÃ©n corriendo
   ```

2. **Acceder a n8n:** http://localhost:5678

3. **Activar workflows en orden:**
   âš ï¸ **Estado actual**: `JSON Lab Data Processing` estÃ¡ activo
   - âœ… **Primero**: `JSON Lab Data Processing` (ACTIVO) - Genera los datos base cada hora
   - **Segundo**: `Lab Alert Monitoring` (INACTIVO) - Monitorea los datos generados
   - **Tercero**: `Lab Data Processing Pipeline` (INACTIVO) - Para procesamiento manual

4. **Verificar funcionamiento:**
   ```bash
   # Comprobar registros procesados
   docker exec lab_postgres psql -U lab_user -d lab_analytics -c "SELECT COUNT(*) FROM processed_lab_data;"
   ```

### **ğŸ¯ Resultado Esperado:**
- `processed_lab_data`: 37 registros (del CSV original)
- `lab_statistics`: 1+ registros de estadÃ­sticas
- Alertas automÃ¡ticas funcionando cada 5 segundos

---

## ğŸš€ **TECNOLOGÃAS**

- **n8n**: Orquestador de workflows
- **FastAPI**: APIs de servicios
- **PostgreSQL**: Base de datos
- **Python**: Procesamiento de datos
- **Docker**: ContenedorizaciÃ³n
- **Pandas**: ManipulaciÃ³n de datos

## ğŸ“Š CaracterÃ­sticas

- âœ… **Procesamiento automÃ¡tico de datos quÃ­micos** basado en CSV de producciÃ³n
- âœ… **NormalizaciÃ³n de equipos quÃ­micos** (phmetro, espectrofotÃ³metro, centrÃ­fuga, analizador hematolÃ³gico)
- âœ… **DetecciÃ³n de anomalÃ­as en rendimiento quÃ­mico** (<75% threshold)
- âœ… **Monitoreo de muestras procesadas** por turno y equipo
- âœ… **Sistema de alertas quÃ­micas** multinivel (crÃ­ticas/medias/advertencias)
- âœ… **Base de datos n8n PostgreSQL** con estructura quÃ­mica optimizada
- âœ… **API REST para integraciÃ³n** con endpoints especÃ­ficos para datos quÃ­micos
- âœ… **Monitoreo en tiempo real** cada 5 segundos
- âœ… **Arquitectura escalable y modular** con Docker
- âœ… **GestiÃ³n de turnos** (maÃ±ana/tarde/noche) con anÃ¡lisis de distribuciÃ³n
- âœ… **Control de calidad** con estados (Aprobado/Repetir) y comentarios

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### **Requisitos Previos:**
- Docker y Docker Compose instalados
- Puerto 5678 (n8n) y 5433 (PostgreSQL) disponibles

### **InstalaciÃ³n Paso a Paso:**

```bash
# 1. Clonar el repositorio
git clone <repo>
cd n8n-lab-automation

# 2. Configurar variables de entorno
cp .env.example .env  # Editar con tus credenciales

# 3. Levantar servicios
docker-compose up -d

# 4. Verificar que los servicios estÃ©n corriendo
docker-compose ps
```

### **Variables de Entorno Requeridas:**
AsegÃºrate de configurar estas variables en tu archivo `.env`:
```bash
# n8n Configuration
N8N_BASIC_AUTH_USER=tu_usuario
N8N_BASIC_AUTH_PASSWORD=tu_contraseÃ±a_segura

# PostgreSQL Configuration
POSTGRES_DB=lab_analytics
POSTGRES_USER=tu_usuario_db
POSTGRES_PASSWORD=tu_contraseÃ±a_db_segura
```

### **ConfiguraciÃ³n de n8n:**

1. **Acceder a n8n**: http://localhost:5678
2. **Credenciales iniciales**:
   - Usuario: `[Ver archivo .env]`
   - ContraseÃ±a: `[Ver archivo .env]`

3. **Importar workflow**:
   - Ir a "Workflows" â†’ "Import from file"
   - Seleccionar `workflows/json-data-processing-workflow.json`

4. **Configurar credenciales PostgreSQL**:
   - Nombre: `Lab PostgreSQL`
   - Host: `lab_postgres`
   - Database: `lab_analytics`
   - User: `[Usar valor de POSTGRES_USER del .env]`
   - Password: `[Usar valor de POSTGRES_PASSWORD del .env]`
   - Port: `5432`

5. **Activar el workflow** y verificar ejecuciÃ³n

## ğŸŒ **INTERFACES DE ACCESO**

### ğŸ¯ **Dashboard Principal - n8n**
- **URL**: http://localhost:5678
- **Usuario**: `[Ver archivo .env]`
- **ContraseÃ±a**: `[Ver archivo .env]`
- **FunciÃ³n**: Crear workflows, monitorear datos, automatizar procesos

### ğŸ—„ï¸ **Base de Datos PostgreSQL**
- **Host**: localhost
- **Puerto**: `5433` (Â¡Importante! No es el 5432 estÃ¡ndar)
- **Base de datos**: `lab_analytics`
- **Usuario**: `[Ver archivo .env]`
- **ContraseÃ±a**: `[Ver archivo .env]`

## ğŸ”’ **Seguridad y Mejores PrÃ¡cticas**

### **âš ï¸ IMPORTANTE - Datos Sensibles:**
- **NUNCA** commitear el archivo `.env` al repositorio
- Usar contraseÃ±as fuertes y Ãºnicas para cada servicio
- Cambiar las credenciales por defecto antes de usar en producciÃ³n
- Mantener las credenciales en variables de entorno, no en cÃ³digo

### **ConfiguraciÃ³n Segura:**
```bash
# Generar contraseÃ±as seguras
openssl rand -base64 32  # Para PostgreSQL
openssl rand -base64 16  # Para n8n

# Verificar que .env no estÃ© en git
git status  # .env NO debe aparecer en la lista
```

### **Acceso Restringido:**
- Cambiar puertos por defecto en producciÃ³n
- Usar HTTPS en lugar de HTTP
- Configurar firewall para limitar acceso a puertos especÃ­ficos
- Implementar autenticaciÃ³n de dos factores cuando sea posible

## ğŸ” **VerificaciÃ³n del Sistema**

### **Comprobar que los datos se estÃ¡n guardando:**

```bash
# Verificar registros en lab_statistics
docker exec lab_postgres psql -U $POSTGRES_USER -d lab_analytics -c "SELECT COUNT(*) FROM lab_statistics;"

# Ver Ãºltimos registros procesados
docker exec lab_postgres psql -U $POSTGRES_USER -d lab_analytics -c "SELECT * FROM processed_lab_data ORDER BY record_id DESC LIMIT 5;"

# Verificar estadÃ­sticas por fecha
docker exec lab_postgres psql -U $POSTGRES_USER -d lab_analytics -c "SELECT fecha, total_records, turnos_unicos, equipos_unicos FROM lab_statistics ORDER BY fecha DESC;"
```

## ğŸš¨ **Troubleshooting**

### **Problemas Comunes:**

1. **Error de credenciales en n8n:**
   - Verificar que las credenciales PostgreSQL estÃ©n configuradas correctamente
   - Usar `lab_postgres` como host (no `localhost`)
   - Verificar que las credenciales coincidan con las del archivo `.env`

2. **Workflow no se ejecuta:**
   - Verificar que el workflow estÃ© activado
   - Comprobar que el archivo JSON existe en `data/produccion_limpia_final.json`
   - Revisar los logs de ejecuciÃ³n en n8n

3. **Contenedores no inician:**
   ```bash
   # Verificar estado de contenedores
   docker-compose ps
   
   # Ver logs de errores
   docker-compose logs n8n
   docker-compose logs postgres
   ```

4. **Base de datos no conecta:**
   - Verificar que PostgreSQL estÃ© corriendo en puerto 5433
   - Comprobar conectividad de red entre contenedores
   ```bash
   docker exec lab_n8n ping lab_postgres
   ```

## ğŸ“ˆ Workflows Disponibles

1. **Procesamiento Diario**: AnÃ¡lisis automÃ¡tico de datos diarios
2. **Alertas de Rendimiento**: Notificaciones por bajo rendimiento
3. **Reportes Semanales**: GeneraciÃ³n automÃ¡tica de informes
4. **Backup de Datos**: Respaldo automÃ¡tico de informaciÃ³n procesada